{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "rXuqbqHi2BSO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Z6bFot2Oeg"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "WXYdSwui2LKL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/s/64ol9q9ssggz6f1/data_ford_price.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Wkm_a7aj2Sk_"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('data\\data_ford_price.xlsx') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "z4vgpzDc2Wlh"
      },
      "outputs": [],
      "source": [
        "y = data['price']\n",
        "X = data.drop(columns='price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Woo8G12avl"
      },
      "source": [
        "# Предобработка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "qAeVTF4N2YLb",
        "outputId": "bf4b235c-c2c7-4615-fcba-d27f4e021ada"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'clean'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lr \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 2\u001b[0m lr\u001b[39m.\u001b[39;49mfit(X,y)\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m )\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'clean'"
          ]
        }
      ],
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWNgsXjv3LTK"
      },
      "source": [
        "_______________________\n",
        "Сторонний пример"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugcPTwHa3OgT",
        "outputId": "6b79c10f-fcd0-4a8a-cd5b-434a10f23cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "категории: ['BSc' 'MSc' 'PhD' 'начальное' 'нет' 'среднее']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing  import LabelBinarizer\n",
        " \n",
        "lb = LabelBinarizer()\n",
        " \n",
        "education = ['нет', 'начальное', 'среднее', 'BSc', 'MSc', 'начальное', 'PhD']\n",
        "lb.fit(education)\n",
        " \n",
        "print('категории:', lb.classes_) \n",
        "lb.transform(['нет', 'MSc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTiDn83d3S7s"
      },
      "source": [
        "___________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjBKN113APL",
        "outputId": "e1344eb5-7be9-47e2-ae5d-b0a9823adb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Число уникальных значений призкака cylinders:  6\n",
            "Число уникальных значений призкака title_status:  5\n",
            "Число уникальных значений призкака transmission:  3\n",
            "Число уникальных значений призкака drive:  3\n",
            "Число уникальных значений призкака size:  4\n"
          ]
        }
      ],
      "source": [
        "columns_to_change = ['cylinders', 'title_status', 'transmission', 'drive', 'size']\n",
        " \n",
        "for column in columns_to_change:\n",
        " print('Число уникальных значений призкака {}: '.format(column), data[column].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDYtJ8wu3cdH",
        "outputId": "60e0daa1-f4f7-449d-e584-ea5c86c85cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cylinders_3' 'cylinders_4' 'cylinders_5' 'cylinders_6' 'cylinders_8'\n",
            " 'cylinders_10' 'title_status_clean' 'title_status_lien'\n",
            " 'title_status_missing' 'title_status_rebuilt' 'title_status_salvage'\n",
            " 'transmission_automatic' 'transmission_manual' 'transmission_other'\n",
            " 'drive_4wd' 'drive_fwd' 'drive_rwd' 'drive_nan' 'size_compact'\n",
            " 'size_full-size' 'size_mid-size' 'size_sub-compact' 'size_nan']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        " \n",
        "one_hot_encoder = OneHotEncoder()\n",
        " \n",
        "# 'учим' и сразу применяем преобразование к выборке, результат переводим в массив\n",
        "data_onehot = one_hot_encoder.fit_transform(data[columns_to_change]).toarray() \n",
        "# запишем полученные названия новых колонок в отдельную переменную\n",
        "column_names = one_hot_encoder.get_feature_names_out(columns_to_change)\n",
        "print(column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_onehot = pd.DataFrame(data_onehot, index=data.index, columns=column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_new = pd.concat([data, data_onehot], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_new = data_new.drop(columns=columns_to_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7017, 30)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7017 entries, 0 to 7016\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   price         7017 non-null   int64  \n",
            " 1   year          7017 non-null   int64  \n",
            " 2   condition     7017 non-null   int64  \n",
            " 3   cylinders     7017 non-null   int64  \n",
            " 4   odometer      7017 non-null   int64  \n",
            " 5   title_status  7017 non-null   object \n",
            " 6   transmission  7017 non-null   object \n",
            " 7   drive         6626 non-null   object \n",
            " 8   size          5453 non-null   object \n",
            " 9   lat           7017 non-null   float64\n",
            " 10  long          7017 non-null   float64\n",
            " 11  weather       6837 non-null   float64\n",
            "dtypes: float64(3), int64(5), object(4)\n",
            "memory usage: 658.0+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.78"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "round((data[~data['size'].isna()].shape[0]/data.shape[0]),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = X.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = y.iloc[x.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_onehot = one_hot_encoder.fit_transform(X_train[columns_to_change]).toarray()\n",
        "X_test_onehot = one_hot_encoder.transform(X_test[columns_to_change]).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['cylinders_3', 'cylinders_4', 'cylinders_5', 'cylinders_6',\n",
              "       'cylinders_8', 'cylinders_10', 'title_status_clean',\n",
              "       'title_status_lien', 'title_status_missing',\n",
              "       'title_status_rebuilt'], dtype=object)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = one_hot_encoder.get_feature_names_out(columns_to_change)\n",
        "columns[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_onehot_df = pd.DataFrame(X_train_onehot, columns=columns)\n",
        "X_test_onehot_df = pd.DataFrame(X_test_onehot, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
        "X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
        " \n",
        "y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
        "y_test = y_test.reset_index().drop(['index'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
        "X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
        " \n",
        "X_train_new = X_train_new.drop(columns=columns_to_change)\n",
        "X_test_new = X_test_new.drop(columns=columns_to_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_model.fit(X_train_new, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_predict = lr_model.predict(X_train_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train R^2: 0.647\n",
            "Test R^2: 0.693\n"
          ]
        }
      ],
      "source": [
        "y_test_predict = lr_model.predict(X_test_new)\n",
        "print(\"Train R^2: {:.3f}\".format(r2_score(y_train, y_train_predict)))\n",
        "print(\"Test R^2: {:.3f}\".format(r2_score(y_test, y_test_predict)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        " \n",
        "X_train['weather'] = X_train['weather'].fillna(np.round(np.mean(X_train['weather']),0))\n",
        "X_test['weather'] = X_test['weather'].fillna(np.round(np.mean(X_train['weather']),0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4wd    0.736602\n",
              "Name: drive, dtype: float64"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train['drive'].value_counts(True).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "full-size    0.830089\n",
              "Name: size, dtype: float64"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train['size'].value_counts(True).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train['size'] = X_train['size'].fillna('full-size')\n",
        "X_train['drive'] = X_train['drive'].fillna('4wd')\n",
        " \n",
        "X_test['size'] = X_test['size'].fillna('full-size')\n",
        "X_test['drive'] = X_test['drive'].fillna('4wd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[113], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# Закодируем категориальные признаки (обучаем кодировщик только на тренировочной выборке)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m X_train_onehot \u001b[39m=\u001b[39m one_hot_encoder\u001b[39m.\u001b[39mfit_transform(X_train[categorial_cols])\u001b[39m#.toarray()\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m X_test_onehot \u001b[39m=\u001b[39m one_hot_encoder\u001b[39m.\u001b[39;49mtransform(X_test[categorial_cols])\u001b[39m#.toarray()\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# Результаты преобразуем обратно в DataFrame для удобства\u001b[39;00m\n\u001b[0;32m     27\u001b[0m columns \u001b[39m=\u001b[39m one_hot_encoder\u001b[39m.\u001b[39mget_feature_names_out(categorial_cols)\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:917\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m    913\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[0;32m    914\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    915\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    916\u001b[0m }\n\u001b[1;32m--> 917\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[0;32m    918\u001b[0m     X,\n\u001b[0;32m    919\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[0;32m    920\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    921\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39;49mwarn_on_unknown,\n\u001b[0;32m    922\u001b[0m )\n\u001b[0;32m    923\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_infrequent_categories(X_int, X_mask)\n\u001b[0;32m    925\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:156\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 156\u001b[0m X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(\n\u001b[0;32m    157\u001b[0m     X, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    160\u001b[0m X_int \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_samples, n_features), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m    161\u001b[0m X_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((n_samples, n_features), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:62\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[1;34m(self, X, force_all_finite)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_features):\n\u001b[0;32m     61\u001b[0m     Xi \u001b[39m=\u001b[39m _safe_indexing(X, indices\u001b[39m=\u001b[39mi, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     Xi \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m     63\u001b[0m         Xi, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49mneeds_validation\n\u001b[0;32m     64\u001b[0m     )\n\u001b[0;32m     65\u001b[0m     X_columns\u001b[39m.\u001b[39mappend(Xi)\n\u001b[0;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m X_columns, n_samples, n_features\n",
            "File \u001b[1;32mc:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
            "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
          ]
        }
      ],
      "source": [
        "# Импортируем необходимые модули\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Скопируем данные в отдельную переменную\n",
        "data = x.copy()\n",
        " \n",
        "# В качестве тестовой выборки возьмем строки с пропусками в признаке weather\n",
        "test_data = data[data['weather'].isnull()]\n",
        "# И удалим эти строчки из таблицы\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Определим целевой признак и факторы\n",
        "y_train = data['weather']\n",
        "X_train = data.drop(['size','weather','drive'], axis=1)\n",
        "X_test = test_data.drop(['size','weather','drive'], axis=1)\n",
        "\n",
        "# Создадим кодировщик\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "categorial_cols = ['cylinders', 'title_status', 'transmission']\n",
        "\n",
        "# Закодируем категориальные признаки (обучаем кодировщик только на тренировочной выборке)\n",
        "X_train_onehot = one_hot_encoder.fit_transform(X_train[categorial_cols])#.toarray()\n",
        "X_test_onehot = one_hot_encoder.transform(X_test[categorial_cols])#.toarray()\n",
        "\n",
        "# Результаты преобразуем обратно в DataFrame для удобства\n",
        "columns = one_hot_encoder.get_feature_names_out(categorial_cols)\n",
        "X_train_onehot_df = pd.DataFrame(X_train_onehot, columns=columns)\n",
        "X_test_onehot_df = pd.DataFrame(X_test_onehot, columns=columns)\n",
        "\n",
        "# Сбросим индексы таблиц\n",
        "X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
        "X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
        "y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
        "\n",
        "# Добавим результаты кодирования к исходным таблицам\n",
        "X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
        "X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
        "\n",
        "# Удалим столбцы, которые уже были закодированы\n",
        "X_train_new = X_train_new.drop(columns=categorial_cols)\n",
        "X_test_new = X_test_new.drop(columns=categorial_cols)\n",
        "\n",
        "# Создадим модель линейной регрессии и обучим ее на задачу предсказания пропусков\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_new, y_train)\n",
        "\n",
        "# Сделаем предсказание целевой переменной (пропущенных значений в признаке weather) \n",
        "y_pred = model.predict(X_test_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>odometer</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>weather</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016</td>\n",
              "      <td>6</td>\n",
              "      <td>43500</td>\n",
              "      <td>36.471500</td>\n",
              "      <td>-82.483400</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>8</td>\n",
              "      <td>98131</td>\n",
              "      <td>40.468826</td>\n",
              "      <td>-74.281734</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>8</td>\n",
              "      <td>201803</td>\n",
              "      <td>42.477134</td>\n",
              "      <td>-82.949564</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>8</td>\n",
              "      <td>170305</td>\n",
              "      <td>40.764373</td>\n",
              "      <td>-82.349503</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2003</td>\n",
              "      <td>8</td>\n",
              "      <td>167662</td>\n",
              "      <td>45.518031</td>\n",
              "      <td>-122.578752</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  cylinders  odometer        lat        long  weather\n",
              "0  2016          6     43500  36.471500  -82.483400     59.0\n",
              "1  2009          8     98131  40.468826  -74.281734     52.0\n",
              "2  2002          8    201803  42.477134  -82.949564     45.0\n",
              "3  2000          8    170305  40.764373  -82.349503     49.0\n",
              "5  2003          8    167662  45.518031 -122.578752     50.0"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[['price', 'year', 'cylinders', 'odometer' ,'lat', 'long', 'weather']]\n",
        "data.dropna(inplace = True)\n",
        " \n",
        "y = data['price']\n",
        "x = data.drop(columns='price')\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 4856.318\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=30)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_predicted = model.predict(X_test)\n",
        " \n",
        "mae = mean_absolute_error(y_test, y_predicted)\n",
        "print('MAE: %.3f' % mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\u1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2544, 6) (2544,)\n",
            "MAE: 4882.332\n"
          ]
        }
      ],
      "source": [
        "from  sklearn.ensemble import IsolationForest\n",
        " \n",
        "# ищем выбросы в обучающей выборке\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "y_predicted = iso.fit_predict(X_train)\n",
        " \n",
        "# выберем все строки, которые не являются выбросами\n",
        "mask = y_predicted != -1\n",
        "X_train, y_train = X_train[mask], y_train[mask]\n",
        " \n",
        "print(X_train.shape, y_train.shape)\n",
        " \n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        " \n",
        "y_predicted = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_predicted)\n",
        "print('MAE: %.3f' % mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2409, 6) (2409,)\n",
            "MAE: 4917.934\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        " \n",
        "lof = LocalOutlierFactor()\n",
        "y_predicted = lof.fit_predict(X_train)\n",
        "\n",
        "mask = y_predicted != -1\n",
        "X_train, y_train = X_train[mask], y_train[mask]\n",
        " \n",
        "print(X_train.shape, y_train.shape)\n",
        " \n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        " \n",
        "y_predicted = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_predicted)\n",
        "print('MAE: %.3f' % mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2385, 6) (2385,)\n",
            "MAE: 4931.482\n"
          ]
        }
      ],
      "source": [
        "from sklearn.covariance import EllipticEnvelope\n",
        " \n",
        "ee = EllipticEnvelope(contamination=0.01)\n",
        "y_predicted = ee.fit_predict(X_train)\n",
        "\n",
        "mask = y_predicted != -1\n",
        "X_train, y_train = X_train[mask], y_train[mask]\n",
        " \n",
        "print(X_train.shape, y_train.shape)\n",
        " \n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        " \n",
        "y_predicted = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_predicted)\n",
        "print('MAE: %.3f' % mae)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Кодирование_признаков.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
